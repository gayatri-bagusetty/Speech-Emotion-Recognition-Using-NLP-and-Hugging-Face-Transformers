{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBWqMlHw0V57vxT3UCy39o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gayatri-bagusetty/Speech-Emotion-Recognition-Using-NLP-and-Hugging-Face-Transformers/blob/main/Speech_Emotion_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dqXpPl0HWvT",
        "outputId": "8cd281bb-968f-4fb9-db1d-4dfe574547d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pipwin\n",
            "  Downloading pipwin-0.5.2.tar.gz (7.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting docopt (from pipwin)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pipwin) (2.32.3)\n",
            "Collecting pyprind (from pipwin)\n",
            "  Downloading PyPrind-2.11.3-py2.py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from pipwin) (1.17.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from pipwin) (4.13.3)\n",
            "Collecting js2py (from pipwin)\n",
            "  Downloading Js2Py-0.74-py3-none-any.whl.metadata (868 bytes)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pipwin) (24.2)\n",
            "Collecting pySmartDL>=1.3.1 (from pipwin)\n",
            "  Downloading pySmartDL-1.3.4-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.9.0->pipwin) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.9.0->pipwin) (4.12.2)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.11/dist-packages (from js2py->pipwin) (5.2)\n",
            "Collecting pyjsparser>=2.5.1 (from js2py->pipwin)\n",
            "  Downloading pyjsparser-2.7.1.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pipwin) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pipwin) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pipwin) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pipwin) (2025.1.31)\n",
            "Downloading pySmartDL-1.3.4-py3-none-any.whl (20 kB)\n",
            "Downloading Js2Py-0.74-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyPrind-2.11.3-py2.py3-none-any.whl (8.4 kB)\n",
            "Building wheels for collected packages: pipwin, docopt, pyjsparser\n",
            "  Building wheel for pipwin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pipwin: filename=pipwin-0.5.2-py2.py3-none-any.whl size=8766 sha256=2de41c5acbe567d6e50aa0169c1989fa6cdba6ffab031308431389fe3398c3d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/45/2e/51ee464b7c3407327439df34c2fc62f978a1e5084aaf23d201\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=4560671bbb6b7d21d0e86818cd84f80578741ee207ffb1563dff670fc43de949\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
            "  Building wheel for pyjsparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyjsparser: filename=pyjsparser-2.7.1-py3-none-any.whl size=25983 sha256=8162c5edac6dee75b4482525fe35bc23f389167bb373a2e2089e40528852343e\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/9a/30/1003e89ab4555b81840ca46d361bf184f1e6ad880cae3b62a9\n",
            "Successfully built pipwin docopt pyjsparser\n",
            "Installing collected packages: pySmartDL, pyprind, pyjsparser, docopt, js2py, pipwin\n",
            "Successfully installed docopt-0.6.2 js2py-0.74 pipwin-0.5.2 pySmartDL-1.3.4 pyjsparser-2.7.1 pyprind-2.11.3\n"
          ]
        }
      ],
      "source": [
        "!pip install pipwin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install portaudio19-dev\n",
        "!pip install pyaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhCFoT8bIuIH",
        "outputId": "8df65336-5aaa-44ee-e8d3-e3bdbc3f6589"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libportaudio2 libportaudiocpp0\n",
            "Suggested packages:\n",
            "  portaudio19-doc\n",
            "The following NEW packages will be installed:\n",
            "  libportaudio2 libportaudiocpp0 portaudio19-dev\n",
            "0 upgraded, 3 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 188 kB of archives.\n",
            "After this operation, 927 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudio2 amd64 19.6.0-1.1 [65.3 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudiocpp0 amd64 19.6.0-1.1 [16.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 portaudio19-dev amd64 19.6.0-1.1 [106 kB]\n",
            "Fetched 188 kB in 1s (279 kB/s)\n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "(Reading database ... 124926 files and directories currently installed.)\n",
            "Preparing to unpack .../libportaudio2_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Selecting previously unselected package libportaudiocpp0:amd64.\n",
            "Preparing to unpack .../libportaudiocpp0_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
            "Selecting previously unselected package portaudio19-dev:amd64.\n",
            "Preparing to unpack .../portaudio19-dev_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Setting up libportaudiocpp0:amd64 (19.6.0-1.1) ...\n",
            "Setting up portaudio19-dev:amd64 (19.6.0-1.1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "Collecting pyaudio\n",
            "  Using cached PyAudio-0.2.14.tar.gz (47 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pyaudio\n",
            "  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyaudio: filename=PyAudio-0.2.14-cp311-cp311-linux_x86_64.whl size=67394 sha256=da755802bf50dd57f775b7f84912a8b352eb6ed540bd27a3d8b6cb7a9f9cc120\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/b1/c1/67e4ef443de2665d86031d4760508094eab5de37d5d64d9c27\n",
            "Successfully built pyaudio\n",
            "Installing collected packages: pyaudio\n",
            "Successfully installed pyaudio-0.2.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition pyaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLj2qWlwHoZC",
        "outputId": "39d67cea-bbf9-4983-89af-1785f92c976b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Using cached SpeechRecognition-3.14.1-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: pyaudio in /usr/local/lib/python3.11/dist-packages (0.2.14)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from SpeechRecognition) (4.12.2)\n",
            "Using cached SpeechRecognition-3.14.1-py3-none-any.whl (32.9 MB)\n",
            "Installing collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --user -U nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sp3cNZurHq-8",
        "outputId": "20a8e7ed-9798-42a8-e679-adb1145f8763"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ONE AUDIO FILE AND TEXT**"
      ],
      "metadata": {
        "id": "TN6W2wK8HunO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import string\n",
        "import nltk\n",
        "import torch\n",
        "import speech_recognition as sr\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from transformers import pipeline\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Load Hugging Face emotion detection model\n",
        "emotion_classifier = pipeline(\"text-classification\", model=\"bhadresh-savani/distilbert-base-uncased-emotion\")\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Clean and preprocess text.\"\"\"\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
        "    words = word_tokenize(text)  # Tokenize words\n",
        "\n",
        "    # Handle missing stopwords safely\n",
        "    try:\n",
        "        stop_words = set(stopwords.words('english')) - {\"not\", \"no\", \"nor\"}  # Keep negations\n",
        "    except LookupError:\n",
        "        nltk.download('stopwords')\n",
        "        stop_words = set(stopwords.words('english')) - {\"not\", \"no\", \"nor\"}\n",
        "\n",
        "    words = [word for word in words if word not in stop_words]  # Remove stopwords\n",
        "    return \" \".join(words)\n",
        "\n",
        "def detect_emotion(text):\n",
        "    \"\"\"Detect emotion from text using Hugging Face model.\"\"\"\n",
        "    if not text:\n",
        "        return \"No text provided.\"\n",
        "\n",
        "    # Preprocess text\n",
        "    cleaned_text = preprocess_text(text)\n",
        "\n",
        "    # Get emotion prediction\n",
        "    emotion = emotion_classifier(cleaned_text)\n",
        "    return emotion[0]['label']\n",
        "\n",
        "def speech_to_text(audio_file):\n",
        "    \"\"\"Convert speech to text using SpeechRecognition.\"\"\"\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    try:\n",
        "        with sr.AudioFile(audio_file) as source:\n",
        "            print(\"Listening...\")\n",
        "            audio = recognizer.record(source)\n",
        "\n",
        "        text = recognizer.recognize_google(audio)\n",
        "        print(f\"Transcribed Text: {text}\")\n",
        "        return text\n",
        "    except sr.UnknownValueError:\n",
        "        return \"Sorry, could not understand the audio.\"\n",
        "    except sr.RequestError as e:\n",
        "        return f\"Speech Recognition API Error: {e}\"\n",
        "\n",
        "# Test Emotion Analysis\n",
        "sample_texts = [\n",
        "    \"I am so happy today!\",\n",
        "    \"I am really angry at you!\",\n",
        "    \"That was a scary experience!\",\n",
        "    \"I feel so loved and cherished.\",\n",
        "    \"I am heartbroken and so sad.\"\n",
        "]\n",
        "\n",
        "for text in sample_texts:\n",
        "    print(f\"Input: {text} -> Emotion: {detect_emotion(text)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23gZRq31Hsi9",
        "outputId": "dc2b4961-cb26-4889-f65b-036fc72335c0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: I am so happy today! -> Emotion: joy\n",
            "Input: I am really angry at you! -> Emotion: anger\n",
            "Input: That was a scary experience! -> Emotion: fear\n",
            "Input: I feel so loved and cherished. -> Emotion: love\n",
            "Input: I am heartbroken and so sad. -> Emotion: sadness\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATASET**"
      ],
      "metadata": {
        "id": "T2_OXpd1H8Xn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Z1FBIDaH3Ye",
        "outputId": "ea5faa03-0bf7-4204-bf54-53b4af6992c5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import string\n",
        "import nltk\n",
        "import torch\n",
        "import speech_recognition as sr\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from transformers import pipeline\n",
        "from datetime import datetime  # Timestamp handling\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load Hugging Face emotion detection model\n",
        "emotion_classifier = pipeline(\"text-classification\", model=\"bhadresh-savani/distilbert-base-uncased-emotion\")\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Clean and preprocess text.\"\"\"\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
        "    words = word_tokenize(text)  # Tokenize words\n",
        "\n",
        "    # Handle missing stopwords safely\n",
        "    try:\n",
        "        stop_words = set(stopwords.words('english')) - {\"not\", \"no\", \"nor\"}  # Keep negations\n",
        "    except LookupError:\n",
        "        nltk.download('stopwords')\n",
        "        stop_words = set(stopwords.words('english')) - {\"not\", \"no\", \"nor\"}\n",
        "\n",
        "    words = [word for word in words if word not in stop_words]  # Remove stopwords\n",
        "    return \" \".join(words)\n",
        "\n",
        "def detect_emotion(text):\n",
        "    \"\"\"Detect emotion from text using Hugging Face model.\"\"\"\n",
        "    if not text:\n",
        "        return \"No text provided.\"\n",
        "\n",
        "    # Preprocess text\n",
        "    cleaned_text = preprocess_text(text)\n",
        "\n",
        "    # Get emotion prediction\n",
        "    emotion = emotion_classifier(cleaned_text)\n",
        "    return emotion[0]['label']\n",
        "\n",
        "def speech_to_text(audio_file):\n",
        "    \"\"\"Convert speech to text from an audio file.\"\"\"\n",
        "    recognizer = sr.Recognizer()\n",
        "    try:\n",
        "        with sr.AudioFile(audio_file) as source:\n",
        "            print(f\"üé§ Processing: {audio_file}\")\n",
        "            audio = recognizer.record(source)\n",
        "\n",
        "        text = recognizer.recognize_google(audio)\n",
        "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")  # Get current timestamp\n",
        "        return text, timestamp\n",
        "    except sr.UnknownValueError:\n",
        "        return \"Could not understand the audio.\", None\n",
        "    except sr.RequestError as e:\n",
        "        return f\"Speech Recognition API Error: {e}\", None\n",
        "\n",
        "def process_audio_dataset(dataset_folder):\n",
        "    \"\"\"Process multiple audio files in a dataset folder.\"\"\"\n",
        "    if not os.path.exists(dataset_folder):\n",
        "        print(\"Dataset folder not found.\")\n",
        "        return\n",
        "\n",
        "    for file in os.listdir(dataset_folder):\n",
        "        if file.endswith(\".wav\") or file.endswith(\".mp3\"):\n",
        "            audio_path = os.path.join(dataset_folder, file)\n",
        "            spoken_text, speech_time = speech_to_text(audio_path)\n",
        "            if spoken_text and speech_time:\n",
        "                detected_emotion = detect_emotion(spoken_text)\n",
        "                print(f\"üìù File: {file} | ‚è±Ô∏è Timestamp: {speech_time} | üó£Ô∏è Text: {spoken_text} | üí° Emotion: {detected_emotion}\")\n",
        "\n",
        "# Set the path to your dataset folder\n",
        "dataset_folder = \"/content/drive/MyDrive/NLP\"  # Change this to your actual folder path\n",
        "process_audio_dataset(dataset_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBXbolrpH4UZ",
        "outputId": "794eb9f3-d2c7-4d6f-cf79-974dd5e53459"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üé§ Processing: /content/drive/MyDrive/NLP/OSR_us_000_0011_8k.wav\n",
            "üìù File: OSR_us_000_0011_8k.wav | ‚è±Ô∏è Timestamp: 2025-02-16 14:35:20 | üó£Ô∏è Text: the boy was there when the sun rose a rod is used to catch pink salmon the source of the huge river is the Clear Spring kick the ball straight and follow through help the women get back to her feet a pot of tea helps to pass the evening Smoky fires black flame in heat the soft cushion broke the man's fall the salt Breeze came across the sea the girl at the booth sold 50 bonds | üí° Emotion: sadness\n",
            "üé§ Processing: /content/drive/MyDrive/NLP/OSR_us_000_0061_8k.wav\n",
            "üìù File: OSR_us_000_0061_8k.wav | ‚è±Ô∏è Timestamp: 2025-02-16 14:35:38 | üó£Ô∏è Text: the mute muffled the high tones of the horn the gold ring fits only appears to ear the old pan was covered with hard fudge watch the log float in the wide river the node on the stock of wheat grow daily the Heap of fallen leaves was set on fire right fast if you want to finish early his shirt was clean but one button was gone the barrel of beer was a brew of malt and hops tin cans or absent from store shelves | üí° Emotion: sadness\n",
            "üé§ Processing: /content/drive/MyDrive/NLP/OSR_us_000_0015_8k.wav\n",
            "üìù File: OSR_us_000_0015_8k.wav | ‚è±Ô∏è Timestamp: 2025-02-16 14:35:49 | üó£Ô∏è Text: the first can you slid on the smooth planks glue the sheet to the dark blue background is easy to tell the depth of a well these days a chicken leg is a rare dish rice is often served in round Bowls the juice of lemons makes fine punch the box was thrown beside the park truck the Hogs are fed chopped corn and garbage 4 hours of study work faced us a large size of stockings is hard to sell | üí° Emotion: anger\n",
            "üé§ Processing: /content/drive/MyDrive/NLP/OSR_us_000_0010_8k.wav\n",
            "üìù File: OSR_us_000_0010_8k.wav | ‚è±Ô∏è Timestamp: 2025-02-16 14:36:03 | üó£Ô∏è Text: the birds canoe slid on the smooth planks glue the sheet to the dark blue background it is easy to tell the depth of a well these days a chicken leg is a rare dish rice is often served in round Bowls the juice of lemons makes fine punch the box was thrown beside the park truck the Hogs are fed chopped corn and garbage 4 hours of study work face does a large size in stockings is hard to sell | üí° Emotion: joy\n",
            "üé§ Processing: /content/drive/MyDrive/NLP/OSR_us_000_0060_8k.wav\n",
            "üìù File: OSR_us_000_0060_8k.wav | ‚è±Ô∏è Timestamp: 2025-02-16 14:36:19 | üó£Ô∏è Text: the horse trotted around the field at a Brisk Pace find the twin who stole the pearl necklace cut the cord that binds the Box tightly the red tape bound the smuggled food look in the corner to find the tan shirt the cold drizzle will halt the Bond drive 9 men were hired to dig the ruins the junkyard had a moldy smell the Flint spider and pine torch soak the cloth and drown the sharp or odor | üí° Emotion: anger\n",
            "üé§ Processing: /content/drive/MyDrive/NLP/OSR_us_000_0059_8k.wav\n",
            "üìù File: OSR_us_000_0059_8k.wav | ‚è±Ô∏è Timestamp: 2025-02-16 14:36:34 | üó£Ô∏è Text: the dark pot hung in the front closet carry the pale to the wall and spill it there the train brought our hero to the big town we are sure that one war is enough gray paint stretched for miles around the root of the empty room High seats are best for football fans teaser from the Brown Jug is tasty a dash of food is the hot cross bun | üí° Emotion: joy\n",
            "üé§ Processing: /content/drive/MyDrive/NLP/OSR_us_000_0037_8k.wav\n",
            "üìù File: OSR_us_000_0037_8k.wav | ‚è±Ô∏è Timestamp: 2025-02-16 14:36:49 | üó£Ô∏è Text: the store walls were lined with colored Fox the peace League met to discuss their plans the rise to fame of a person takes luck paper is scarce so right with much care the quick fox jumped on the sleeping cat the nozzle of the fire hose was bright brass screw the round cat on his tight as needed time brings as many changes the purple tie was 10 years old men think and plan and sometimes Act | üí° Emotion: anger\n",
            "üé§ Processing: /content/drive/MyDrive/NLP/OSR_us_000_0014_8k.wav\n",
            "üìù File: OSR_us_000_0014_8k.wav | ‚è±Ô∏è Timestamp: 2025-02-16 14:37:01 | üó£Ô∏è Text: a King rule the state in the early days the ship was torn apart on the sharp Reef sickness kept him home the third week the wide Road shimmered in the hot sun the lazy cow lay in the choreographed lift the square Stone over the fence the Rope will buy in the seven books I want hop over the fence and plunging friendly gang left the drugstore mesh wire keeps chips inside | üí° Emotion: joy\n",
            "üé§ Processing: /content/drive/MyDrive/NLP/OSR_us_000_0013_8k.wav\n",
            "üìù File: OSR_us_000_0013_8k.wav | ‚è±Ô∏è Timestamp: 2025-02-16 14:37:11 | üó£Ô∏è Text: what's the low to your left shoulder take the winding path to reach the lake note closely the size of the gas tank wipe the grease off his dirty face mend the coat before you go out the wrist was badly strained and hung limp the stray cat gave birth to kittens the young girl gave no clear response the mill was cooked before the bell ring what Joy there is in living | üí° Emotion: sadness\n",
            "üé§ Processing: /content/drive/MyDrive/NLP/OSR_us_000_0012_8k.wav\n",
            "üìù File: OSR_us_000_0012_8k.wav | ‚è±Ô∏è Timestamp: 2025-02-16 14:37:24 | üó£Ô∏è Text: does small pup not a hole in the sock the fish twisted and turn on the bent hook press the pants and sew a button on the vest Swan Dive with far short of perfect the beauty of the view is done the young boy two blue fish swim in the tank her purse was full of useless trash in the same morning read verse out loud for pleasure | üí° Emotion: sadness\n"
          ]
        }
      ]
    }
  ]
}